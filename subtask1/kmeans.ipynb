{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
    "model = AutoModel.from_pretrained(\"bert-base-multilingual-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fi_dev = pd.read_csv('../data/finnish/axolotl.dev.fi.tsv', sep='\\t')\n",
    "df_fi_train = pd.read_csv('../data/finnish/axolotl.train.fi.tsv', sep='\\t')\n",
    "df_ru_dev = pd.read_csv('../data/russian/axolotl.dev.ru.tsv', sep='\\t')\n",
    "df_ru_train = pd.read_csv('../data/russian/axolotl.train.ru.tsv', sep='\\t')\n",
    "df_fi_test = pd.read_csv('../data/test/axolotl.test.fi.tsv', sep='\\t')\n",
    "df_ru_test = pd.read_csv('../data/test/axolotl.test.ru.tsv', sep='\\t')\n",
    "df_surprise = pd.read_csv('../data/test/axolotl.test.surprise.tsv', sep='\\t')\n",
    "\n",
    "all_dfs = {\"russian\": df_ru_train, \"finnish\":  df_fi_train}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2126 entries, 0 to 2125\n",
      "Data columns (total 9 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   usage_id              2126 non-null   object \n",
      " 1   word                  2126 non-null   object \n",
      " 2   orth                  2126 non-null   object \n",
      " 3   sense_id              424 non-null    object \n",
      " 4   gloss                 424 non-null    object \n",
      " 5   example               1990 non-null   object \n",
      " 6   indices_target_token  0 non-null      float64\n",
      " 7   date                  2126 non-null   object \n",
      " 8   period                2126 non-null   object \n",
      "dtypes: float64(1), object(8)\n",
      "memory usage: 149.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df_ru_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_example(word, gloss, example):\n",
    "    if pd.isna(example):\n",
    "        return f\"Определение слова {word}: {gloss}\"\n",
    "    else:\n",
    "        return example\n",
    "df_ru_train['example'] = df_ru_train.apply(lambda row: fill_example(row['word'],row['gloss'], row['example']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6494 entries, 0 to 6493\n",
      "Data columns (total 10 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   usage_id              6494 non-null   object \n",
      " 1   word                  6494 non-null   object \n",
      " 2   orth                  6494 non-null   object \n",
      " 3   sense_id              6494 non-null   object \n",
      " 4   gloss                 6494 non-null   object \n",
      " 5   example               6494 non-null   object \n",
      " 6   indices_target_token  0 non-null      float64\n",
      " 7   date                  6493 non-null   object \n",
      " 8   period                6493 non-null   object \n",
      " 9   embedding             0 non-null      object \n",
      "dtypes: float64(1), object(9)\n",
      "memory usage: 507.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df = df_ru_train\n",
    "df['embedding'] = None\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_nice(input_ids, index):\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "    tokens[index] = '\\033[91m' + tokens[index] + '\\033[0m'\n",
    "    print(' '.join(tokens))\n",
    "\n",
    "def find_word_containing_target(sentence, target_word):\n",
    "    index = sentence.find(target_word)\n",
    "    if index == -1:\n",
    "        return None\n",
    "    start_index = sentence.rfind(\" \", 0, index) + 1 if index != 0 else 0\n",
    "    end_index = sentence.find(\" \", index + len(target_word)) if sentence.find(\" \", index + len(target_word)) != -1 else len(sentence)\n",
    "    return sentence[start_index:end_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_search(sentence, word, orth=None):\n",
    "        found_search = find_word_containing_target(sentence, word)\n",
    "        if found_search:\n",
    "            return found_search\n",
    "        else:\n",
    "            if orth:\n",
    "                found_search = find_word_containing_target(sentence, orth)\n",
    "                if found_search:\n",
    "                    return found_search\n",
    "                else:\n",
    "                    return word\n",
    "            else:\n",
    "                return word\n",
    "\n",
    "def get_target_index(search_token, tokens, tokens_lower):\n",
    "    if search_token in tokens:\n",
    "        return tokens.index(search_token)+1 # +1 for the [CLS] token\n",
    "    elif f\"##{search_token}\" in tokens:\n",
    "        return tokens.index(f\"##{search_token}\")+1\n",
    "    elif search_token in tokens_lower:\n",
    "            return tokens_lower.index(search_token)+1 # +1 for the [CLS] token\n",
    "    elif f\"##{search_token}\" in tokens_lower:\n",
    "            return tokens_lower.index(f\"##{search_token}\")+1\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] О ##пределение слова \u001b[91mмир\u001b[0m ##о : Мир ##о , м ##v ##ро с ##р . , б ##лаг ##ово ##нное ма ##сло , па ##ху ##чая ма ##сть или души ##сто ##е ма ##сл ##ян ##ист ##ое веществ ##о . [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] Затем к ##люч ##ар ##ь при ##гла ##шает , чтобы женщины вышли из ал ##тар ##я [UNK] Под ##а ##ёт свят ##ое \u001b[91mмир\u001b[0m ##о . А ##рх ##ие ##рей пом ##азу ##ет крест ##оо ##бра ##зно сначала т ##ра ##пе ##зу в тех местах , где во время лит ##ург ##ии стоит е ##ван ##гел ##ие , диск ##ос и по ##ти ##р . [SEP]\n",
      "[CLS] Они в ##езде одним м ##v ##ром ма ##зан ##ы . М ##v ##ром по ##крыт ( т . е . пом ##азан ) , с \u001b[91mмир\u001b[0m ##ом за ##с ##пит . Р ##ого ##ж ##цы в [SEP]\n",
      "[CLS] М ##о ##щи святого х ##ран ##ятся здесь до сих пор , про ##до ##лж ##ая исто ##чать \u001b[91mмир\u001b[0m ##о . [SEP]\n",
      "[CLS] И ##осиф у ##вид ##ел , что по и ##кон ##е Бог ##оро ##ди ##цы тек ##ли стр ##уй ##ки \u001b[91mмира\u001b[0m , которое и изд ##ава ##ло б ##лаг ##оу ##хан ##ие . [SEP]\n",
      "миро\n",
      "[CLS] К ##аза ##лось , перед р ##ево ##лю ##цией у ##де ##сят ##ери ##лось о ##жи ##дание , пред ##чу ##в ##ствие , пред ##вид ##ение золото ##го века , р ##ая на земле ; каз ##алось , вся ду ##ша на ##ции и ##сс ##туп ##лен ##но бр ##еди ##ла и гр ##ези ##ла чем - то един ##ым , в котором с ##п ##лета ##лись не ##рас ##тор ##жим ##о смерть и б ##есс ##мер ##тие , золотой век и ги ##бель , \u001b[91mмог\u001b[0m ##иль ##ный м ##рак и ос ##леп ##ительный свет [UNK] [SEP]\n",
      "[CLS] И первое время в о ##фи ##са ##х трёх компаний сто ##яла \u001b[91mмог\u001b[0m ##иль ##ная ти ##шина , сотрудник ##и об ##щал ##ись друг с другом за ##пис ##очка ##ми , только с ##к ##ри ##пели пер ##ья . [SEP]\n",
      "[CLS] Я по ##гла ##дил ##а сум ##ку , даже через за ##м ##шу рук ##а о ##щу ##тил ##а \u001b[91mмог\u001b[0m ##иль ##ный х ##оло ##д п ##ист ##оле ##та . [SEP]\n",
      "[CLS] памятник , - за ##пах , - на ##я ти ##шина . К ##ом \u001b[91mмог\u001b[0m ##иль ##ной земли к се ##рд ##цу , с ##кор ##б ##ь от ##ля ##же ##т . [SEP]\n",
      "[CLS] М ##оло ##ток ле ##жит на ок ##не [UNK] должно быть , им при ##бива ##ют к \u001b[91mмог\u001b[0m ##иль ##ным крест ##ам до ##ще ##чки . [SEP]\n",
      "10. мог not found, taking [CLS] token... (['М', '##оги', '##льные', 'п', '##лит', '##ы', 'на', 'сто', '##лично', '##м', 'по', '##го', '##сте', 'за', '##рос', '##ли', 'бу', '##рь', '##ян', '##ом', ',', 'крест', '##ы', 'под', '##ко', '##сили', '##сь', ',', 'всё', 'каз', '##алось', 'пов', '##ален', '##ным', 'или', 'при', '##дав', '##лен', '##ным', '.'])\n",
      "\u001b[91m[CLS]\u001b[0m М ##оги ##льные п ##лит ##ы на сто ##лично ##м по ##го ##сте за ##рос ##ли бу ##рь ##ян ##ом , крест ##ы под ##ко ##сили ##сь , всё каз ##алось пов ##ален ##ным или при ##дав ##лен ##ным . [SEP]\n",
      "[CLS] Я [UNK] сл ##аб ##ый , б ##ед ##ный уз ##ник , Что через час за ##с ##н ##ёт \u001b[91mмог\u001b[0m ##иль ##ным с ##ном [UNK] [SEP]\n",
      "могильный\n",
      "[CLS] За ##то она очень л ##ю ##била мы ##ть пол ##ы и исп ##ол ##нял ##а это за ##нятие так часто и с таким усе ##рди ##ем , что в кв ##арт ##ире скоро за ##вела ##сь с ##ыр ##ость и показали ##сь \u001b[91mм\u001b[0m ##ок ##ри ##цы . [SEP]\n",
      "[CLS] [UNK] З ##нае ##шь , до встречи с то ##бой я была така ##я т ##рус ##их ##а , правда , я л ##ы ##жни ##ца и п ##лава ##ю хорошо , у меня первый раз ##ряд , но всё равно я т ##рус ##их ##а , мы ##шей бою ##сь , и \u001b[91mм\u001b[0m ##ок ##ри ##ц , и со ##рок ##он ##оже ##к . [SEP]\n",
      "[CLS] Р ##еб ##яти ##шки , что \u001b[91mм\u001b[0m ##ок ##ри ##цы от с ##ыр ##ости раз ##водятся . [SEP]\n",
      "[CLS] О ##чень долго ( до 15 - 20 лет ) могут со ##х ##ран ##яться в по ##ч ##ве се ##мена со ##рн ##як ##ов : ле ##бед ##ы , ма ##ри , \u001b[91mм\u001b[0m ##ок ##ри ##цы . [SEP]\n",
      "[CLS] В сад ##ике - двор ##ике мал ##ень ##кие к ##лён ##ы , за ##рос ##шая \u001b[91mм\u001b[0m ##ок ##ри ##цей и под ##оро ##жни ##ком уз ##кая т ##ро ##пи ##нка вокруг не ##ров ##ного бу ##гра . [SEP]\n",
      "[CLS] О ##пределение слова \u001b[91mм\u001b[0m ##ок ##ри ##ца : бо ##тан . одно ##лет ##нее т ##рав ##ян ##ист ##ое со ##рно ##е р ##астение семейства г ##во ##зди ##чных с ле ##жа ##чим ##и ст ##еб ##лями и м ##ел ##кими бел ##ыми звёзд ##чат ##ыми цвет ##очка ##ми , р ##аст ##у ##щее в с ##ыры ##х и за ##тен ##ённых местах ( Stella ##ria media ) [SEP]\n",
      "[CLS] \u001b[91mм\u001b[0m ##ок ##ри ##ца , м ##ок ##ри ##чка , [SEP]\n",
      "[CLS] О ##пределение слова \u001b[91mм\u001b[0m ##ок ##ри ##ца : То ##п ##тун , Pol ##yg ##onu ##m av ##icular ##e , с ##пор ##ыш , бр ##ыл ##ёна . [SEP]\n",
      "мокрица\n",
      "[CLS] Но только что он у ##с ##по ##ко ##ился в своей по ##зе , как над сто ##лом про ##лет ##ела \u001b[91mм\u001b[0m ##оль . [SEP]\n",
      "[CLS] \u001b[91mм\u001b[0m ##оль ш ##уб ##ная , п ##лат ##яна ##я , с ##ыр ##ная , [SEP]\n",
      "[CLS] М ##оль ово ##щ ##ная , т ##ля , \u001b[91mм\u001b[0m ##оты ##лица , м ##ет ##лица , которой г ##ус ##ени ##ца по ##еда ##ет со ##ты . [ М ##оль , м ##ел ##ю ##з ##га , м ##ело ##чь , из ##ме ##ль ##чо ##нные в ##е ##щи . [SEP]\n",
      "[CLS] О ##пределение слова \u001b[91mм\u001b[0m ##оль : Сам ##ая м ##ел ##кая р ##ы ##бка , не ##давно вы ##ве ##д ##шая ##ся , м ##оль ##га , м ##оль ##ка , м ##оля ##ва , - л ##яв ##ка , мал ##ь ##га , [SEP]\n",
      "[CLS] \u001b[91mм\u001b[0m ##оль ##ю ; [SEP]\n",
      "[CLS] н ##в ##г . самый \u001b[91mм\u001b[0m ##ел ##кий с ##не ##жок . М ##оль од ##еж ##у т ##лит , а п ##еча ##ль се ##рдце ( или человека ) . На ##бива ##й но ##с та ##ба ##чком , в голов ##е м ##оль не за ##веде ##тся ! На з ##уба ##х м ##оз ##оли , но ##гти р ##ас ##пу ##х ##ли , во ##лос ##а м ##оль [SEP]\n",
      "[CLS] О ##пределение слова \u001b[91mм\u001b[0m ##оль : 2 . м . , в му ##зы ##ке мин ##ор или гр ##ус ##тный ла ##д , м ##яг ##кое со ##зв ##уч ##ье , [SEP]\n",
      "[CLS] М ##оль ##ное отношение r [UNK] число \u001b[91mм\u001b[0m ##олей одного комп ##оне ##нта на один м ##оль другого . [SEP]\n",
      "[CLS] О ##чевидно , что \u001b[91mм\u001b[0m ##оль одного вещества во сто ##лько же раз больше м ##оля другого , во с ##колько раз м ##оле ##кула первого тя ##же ##ле ##е м ##оле ##кул ##ы второго . [SEP]\n",
      "[CLS] М [UNK] ма ##сса 1 \u001b[91mм\u001b[0m ##оль р ##аст ##вор ##ённого вещества ( числе ##нно р ##авная м ##оле ##кул ##яр ##ному в ##ес ##у ) , г . [SEP]\n",
      "моль\n",
      "[CLS] Вы ##г ##лян ##ула из две ##ри , пов ##ис ##нув на ко ##сты ##лях , по ##жила ##я , в ##стр ##ё ##пан ##ная , чи ##та ##ет \u001b[91mмора\u001b[0m ##ль . [SEP]\n",
      "[CLS] Она была их у ##те ##ши ##тель ##ницей , ду ##ше ##пр ##ика ##з ##чи ##цей , каз ##на ##че ##ем , ле ##кар ##ем и дух ##овно ##ю ма ##тер ##ью : ей первой б ##ежа ##л солдат ##ик открыт ##ь св ##ое горе , за ##кл ##ю ##чав ##шее ##ся в по ##тер ##е ш ##тыка , или в ин ##ой под ##обно ##й б ##еде , значения которой не по ##нять тому , кто не носи ##л р ##ан ##ца за п ##ле ##ча ##ми , [UNK] и К ##ат ##ерина А ##ста ##ф ##ьев ##на не чи ##тала ни ##ка ##ких \u001b[91mмора\u001b[0m ##лей и нас ##тав ##лений , а прямо пом ##ога ##ла , как на ##ходил ##а во ##зм ##ожным . [SEP]\n",
      "[CLS] С ##ыта ##я \u001b[91mмора\u001b[0m ##ль ар ##од ##н . ду ##рная слава . Про меня мора ##ль по ##шла . Он на меня мора ##ль на ##водит [SEP]\n",
      "[CLS] Се ##го ##дня в наш ##ем об ##ществе нас ##аж ##дается по ##треби ##тель ##ское мир ##ово ##з ##з ##рение , по ##о ##щ ##ря ##ются э ##го ##исти ##ческие у ##стр ##ем ##ления человека , поп ##ира ##ется х ##ристиан ##ская \u001b[91mмора\u001b[0m ##ль с её жертв ##енно ##стью и у ##стр ##ем ##лен ##ностью к вы ##с ##шим и ##де ##ала ##м . [SEP]\n",
      "34. мора not found, taking [CLS] token... (['М', '##ора', '##ль', 'се', '##й', 'бас', '##ни', 'про', '##ста', 'как', 'правда', ':', 'такое', 'в', 'жизни', 'бы', '##вает', ',', 'что', 'ни', 'в', 'с', '##каз', '##ке', 'с', '##каз', '##ать', ',', 'ни', 'пер', '##ом', 'о', '##писать', '!'])\n",
      "\u001b[91m[CLS]\u001b[0m М ##ора ##ль се ##й бас ##ни про ##ста как правда : такое в жизни бы ##вает , что ни в с ##каз ##ке с ##каз ##ать , ни пер ##ом о ##писать ! [SEP]\n",
      "мораль\n"
     ]
    }
   ],
   "source": [
    "embeddings = []\n",
    "orth = \"\"\n",
    "\n",
    "word_idx = 0\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if orth != \"\" and orth != row['word']:\n",
    "        print(f\"{orth}\")\n",
    "        word_idx += 1\n",
    "    if word_idx == 5:\n",
    "        break\n",
    "\n",
    "    orth = row['word']          # target word\n",
    "    word = row['orth']          # usage of the target word in the example\n",
    "    sense_id = row['sense_id']  # sense of the target word in the example\n",
    "    gloss = row['gloss']        # definition of the target word\n",
    "    example = row['example']    # usage example of the target word\n",
    "\n",
    "    tokens = tokenizer.tokenize(example)\n",
    "    tokens_lower = [i.lower() for i in tokenizer.tokenize(example)]\n",
    "\n",
    "    search = get_search(example, word, orth)\n",
    "    search_token = tokenizer.tokenize(search)[0]\n",
    "    target_index = get_target_index(search_token, tokens, tokens_lower)\n",
    "    if target_index == -1:\n",
    "        search = get_search(example, search_token)\n",
    "        search_token = tokenizer.tokenize(search)[0]\n",
    "        target_index = get_target_index(search_token, tokens, tokens_lower)\n",
    "        if target_index == -1:\n",
    "            print(f\"{index}. {search_token} not found, taking [CLS] token... ({tokens})\")\n",
    "            target_index = 0\n",
    "\n",
    "    inputs = tokenizer(example, return_tensors=\"pt\")\n",
    "    print_nice(inputs['input_ids'][0], target_index)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        input_ids = inputs[\"input_ids\"].to(device)\n",
    "        attention_mask = inputs[\"attention_mask\"].to(device)\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, output_hidden_states=True)\n",
    "    \n",
    "    df.at[index, 'embedding'] = outputs.last_hidden_state[0][target_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6494 entries, 0 to 6493\n",
      "Data columns (total 10 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   usage_id              6494 non-null   object \n",
      " 1   word                  6494 non-null   object \n",
      " 2   orth                  6494 non-null   object \n",
      " 3   sense_id              6494 non-null   object \n",
      " 4   gloss                 6494 non-null   object \n",
      " 5   example               6494 non-null   object \n",
      " 6   indices_target_token  0 non-null      float64\n",
      " 7   date                  6493 non-null   object \n",
      " 8   period                6493 non-null   object \n",
      " 9   embedding             35 non-null     object \n",
      "dtypes: float64(1), object(9)\n",
      "memory usage: 507.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['embedding'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_distance(X, centroids):\n",
    "    return 1 - cosine_similarity(X, centroids)\n",
    "\n",
    "def get_silhouette_score(tensors, labels):\n",
    "    # Convert the torch tensors to numpy arrays and reshape them\n",
    "    X = np.array([tensor.flatten().numpy() for tensor in tensors])\n",
    "    # Calculate the silhouette score\n",
    "    score = silhouette_score(X, labels=labels, metric='euclidean')\n",
    "\n",
    "    return score\n",
    "\n",
    "def KMeans_clustering(df):\n",
    "    best_score = -1\n",
    "    best_n = 0\n",
    "    for n in range(2,5):\n",
    "        kmeans = KMeans(n_clusters=n, random_state=0, metric =cosine_distance)\n",
    "        kmeans.fit(df['embedding'].tolist())\n",
    "        df[f'clusters_{n}'] = None\n",
    "        df[f'clusters_{n}'] = kmeans.labels_\n",
    "        silhouette_avg = get_silhouette_score(df['embedding'], df[f'clusters_{n}'])\n",
    "        if silhouette_avg > best_score:\n",
    "            best_score = silhouette_avg\n",
    "            best_n = n\n",
    "    return df, best_n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: миро\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "KMeans.__init__() got an unexpected keyword argument 'metric'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[120], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m label, group \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mword\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel:\u001b[39m\u001b[38;5;124m\"\u001b[39m, label)\n\u001b[1;32m----> 3\u001b[0m     result_df, best_n \u001b[38;5;241m=\u001b[39m \u001b[43mKMeans_clustering\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_n:\u001b[39m\u001b[38;5;124m\"\u001b[39m, best_n)\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(df)\n",
      "Cell \u001b[1;32mIn[119], line 16\u001b[0m, in \u001b[0;36mKMeans_clustering\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m     14\u001b[0m best_n \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m---> 16\u001b[0m     kmeans \u001b[38;5;241m=\u001b[39m \u001b[43mKMeans\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_clusters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcosine_distance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m     kmeans\u001b[38;5;241m.\u001b[39mfit(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124membedding\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist())\n\u001b[0;32m     18\u001b[0m     df[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclusters_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: KMeans.__init__() got an unexpected keyword argument 'metric'"
     ]
    }
   ],
   "source": [
    "for label, group in df.groupby('word'):\n",
    "    print(\"label:\", label)\n",
    "    result_df, best_n = KMeans_clustering(group)\n",
    "    print(\"best_n:\", best_n)\n",
    "    print(df)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>usage_id</th>\n",
       "      <th>word</th>\n",
       "      <th>orth</th>\n",
       "      <th>sense_id</th>\n",
       "      <th>gloss</th>\n",
       "      <th>example</th>\n",
       "      <th>indices_target_token</th>\n",
       "      <th>date</th>\n",
       "      <th>period</th>\n",
       "      <th>embedding</th>\n",
       "      <th>clusters_2</th>\n",
       "      <th>clusters_3</th>\n",
       "      <th>clusters_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_ru_0</td>\n",
       "      <td>миро</td>\n",
       "      <td>миро</td>\n",
       "      <td>miro_f2cnblJ7iBg</td>\n",
       "      <td>Миро, мvро ср., благовонное масло, пахучая мас...</td>\n",
       "      <td>Определение слова миро: Миро, мvро ср., благов...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>old</td>\n",
       "      <td>old</td>\n",
       "      <td>[tensor(-0.5822), tensor(-0.4083), tensor(0.40...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_ru_1</td>\n",
       "      <td>миро</td>\n",
       "      <td>миро</td>\n",
       "      <td>miro_8igZuzZK97Q</td>\n",
       "      <td>религ. жидкое ароматическое масло, освящаемое ...</td>\n",
       "      <td>Затем ключарь приглашает, чтобы женщины вышли ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>new</td>\n",
       "      <td>new</td>\n",
       "      <td>[tensor(0.4642), tensor(-0.2129), tensor(0.321...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_ru_2</td>\n",
       "      <td>миро</td>\n",
       "      <td>миро</td>\n",
       "      <td>miro_8igZuzZK97Q</td>\n",
       "      <td>религ. жидкое ароматическое масло, освящаемое ...</td>\n",
       "      <td>Они везде одним мvром мазаны. Мvром покрыт (т....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>old</td>\n",
       "      <td>old</td>\n",
       "      <td>[tensor(-0.3496), tensor(-0.1741), tensor(-0.3...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_ru_3</td>\n",
       "      <td>миро</td>\n",
       "      <td>миро</td>\n",
       "      <td>miro_o98UfpSoYH4</td>\n",
       "      <td>религ. жидкость, иногда чудесным образом выдел...</td>\n",
       "      <td>Мощи святого хранятся здесь до сих пор, продол...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>new</td>\n",
       "      <td>new</td>\n",
       "      <td>[tensor(0.0417), tensor(-0.7488), tensor(-0.00...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_ru_4</td>\n",
       "      <td>миро</td>\n",
       "      <td>миро</td>\n",
       "      <td>miro_o98UfpSoYH4</td>\n",
       "      <td>религ. жидкость, иногда чудесным образом выдел...</td>\n",
       "      <td>Иосиф увидел, что по иконе Богородицы текли ст...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>new</td>\n",
       "      <td>new</td>\n",
       "      <td>[tensor(0.0759), tensor(0.0134), tensor(0.2199...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     usage_id  word  orth          sense_id  \\\n",
       "0  train_ru_0  миро  миро  miro_f2cnblJ7iBg   \n",
       "1  train_ru_1  миро  миро  miro_8igZuzZK97Q   \n",
       "2  train_ru_2  миро  миро  miro_8igZuzZK97Q   \n",
       "3  train_ru_3  миро  миро  miro_o98UfpSoYH4   \n",
       "4  train_ru_4  миро  миро  miro_o98UfpSoYH4   \n",
       "\n",
       "                                               gloss  \\\n",
       "0  Миро, мvро ср., благовонное масло, пахучая мас...   \n",
       "1  религ. жидкое ароматическое масло, освящаемое ...   \n",
       "2  религ. жидкое ароматическое масло, освящаемое ...   \n",
       "3  религ. жидкость, иногда чудесным образом выдел...   \n",
       "4  религ. жидкость, иногда чудесным образом выдел...   \n",
       "\n",
       "                                             example  indices_target_token  \\\n",
       "0  Определение слова миро: Миро, мvро ср., благов...                   NaN   \n",
       "1  Затем ключарь приглашает, чтобы женщины вышли ...                   NaN   \n",
       "2  Они везде одним мvром мазаны. Мvром покрыт (т....                   NaN   \n",
       "3  Мощи святого хранятся здесь до сих пор, продол...                   NaN   \n",
       "4  Иосиф увидел, что по иконе Богородицы текли ст...                   NaN   \n",
       "\n",
       "  date period                                          embedding  clusters_2  \\\n",
       "0  old    old  [tensor(-0.5822), tensor(-0.4083), tensor(0.40...           0   \n",
       "1  new    new  [tensor(0.4642), tensor(-0.2129), tensor(0.321...           0   \n",
       "2  old    old  [tensor(-0.3496), tensor(-0.1741), tensor(-0.3...           0   \n",
       "3  new    new  [tensor(0.0417), tensor(-0.7488), tensor(-0.00...           0   \n",
       "4  new    new  [tensor(0.0759), tensor(0.0134), tensor(0.2199...           1   \n",
       "\n",
       "   clusters_3  clusters_4  \n",
       "0           2           3  \n",
       "1           2           2  \n",
       "2           0           0  \n",
       "3           2           2  \n",
       "4           1           1  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LuccasRojas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
    "model = AutoModel.from_pretrained(\"bert-base-multilingual-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fi_dev = pd.read_csv('../data/finnish/axolotl.dev.fi.tsv', sep='\\t')\n",
    "df_fi_train = pd.read_csv('../data/finnish/axolotl.train.fi.tsv', sep='\\t')\n",
    "df_ru_dev = pd.read_csv('../data/russian/axolotl.dev.ru.tsv', sep='\\t')\n",
    "df_ru_train = pd.read_csv('../data/russian/axolotl.train.ru.tsv', sep='\\t')\n",
    "df_fi_test = pd.read_csv('../data/test/axolotl.test.fi.tsv', sep='\\t')\n",
    "df_ru_test = pd.read_csv('../data/test/axolotl.test.ru.tsv', sep='\\t')\n",
    "df_surprise = pd.read_csv('../data/test/axolotl.test.surprise.tsv', sep='\\t')\n",
    "\n",
    "all_dfs = {\"russian\": df_ru_train, \"finnish\":  df_fi_train}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2126 entries, 0 to 2125\n",
      "Data columns (total 9 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   usage_id              2126 non-null   object \n",
      " 1   word                  2126 non-null   object \n",
      " 2   orth                  2126 non-null   object \n",
      " 3   sense_id              424 non-null    object \n",
      " 4   gloss                 424 non-null    object \n",
      " 5   example               1990 non-null   object \n",
      " 6   indices_target_token  0 non-null      float64\n",
      " 7   date                  2126 non-null   object \n",
      " 8   period                2126 non-null   object \n",
      "dtypes: float64(1), object(8)\n",
      "memory usage: 149.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df_ru_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_example(word, gloss, example):\n",
    "    if pd.isna(example):\n",
    "        return f\"Определение слова {word}: {gloss}\"\n",
    "    else:\n",
    "        return example\n",
    "df_ru_train['example'] = df_ru_train.apply(lambda row: fill_example(row['word'],row['gloss'], row['example']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6494 entries, 0 to 6493\n",
      "Data columns (total 10 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   usage_id              6494 non-null   object \n",
      " 1   word                  6494 non-null   object \n",
      " 2   orth                  6494 non-null   object \n",
      " 3   sense_id              6494 non-null   object \n",
      " 4   gloss                 6494 non-null   object \n",
      " 5   example               6494 non-null   object \n",
      " 6   indices_target_token  0 non-null      float64\n",
      " 7   date                  6493 non-null   object \n",
      " 8   period                6493 non-null   object \n",
      " 9   embedding             0 non-null      object \n",
      "dtypes: float64(1), object(9)\n",
      "memory usage: 507.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df = df_ru_train\n",
    "df['embedding'] = None\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_nice(input_ids, index):\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "    tokens[index] = '\\033[91m' + tokens[index] + '\\033[0m'\n",
    "    print(' '.join(tokens))\n",
    "\n",
    "def find_word_containing_target(sentence, target_word):\n",
    "    index = sentence.find(target_word)\n",
    "    if index == -1:\n",
    "        return None\n",
    "    start_index = sentence.rfind(\" \", 0, index) + 1 if index != 0 else 0\n",
    "    end_index = sentence.find(\" \", index + len(target_word)) if sentence.find(\" \", index + len(target_word)) != -1 else len(sentence)\n",
    "    return sentence[start_index:end_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_search(sentence, word, orth=None):\n",
    "        found_search = find_word_containing_target(sentence, word)\n",
    "        if found_search:\n",
    "            return found_search\n",
    "        else:\n",
    "            if orth:\n",
    "                found_search = find_word_containing_target(sentence, orth)\n",
    "                if found_search:\n",
    "                    return found_search\n",
    "                else:\n",
    "                    return word\n",
    "            else:\n",
    "                return word\n",
    "\n",
    "def get_target_index(search_token, tokens, tokens_lower):\n",
    "    if search_token in tokens:\n",
    "        return tokens.index(search_token)+1 # +1 for the [CLS] token\n",
    "    elif f\"##{search_token}\" in tokens:\n",
    "        return tokens.index(f\"##{search_token}\")+1\n",
    "    elif search_token in tokens_lower:\n",
    "            return tokens_lower.index(search_token)+1 # +1 for the [CLS] token\n",
    "    elif f\"##{search_token}\" in tokens_lower:\n",
    "            return tokens_lower.index(f\"##{search_token}\")+1\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] О ##пределение слова \u001b[91mмир\u001b[0m ##о : Мир ##о , м ##v ##ро с ##р . , б ##лаг ##ово ##нное ма ##сло , па ##ху ##чая ма ##сть или души ##сто ##е ма ##сл ##ян ##ист ##ое веществ ##о . [SEP]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] Затем к ##люч ##ар ##ь при ##гла ##шает , чтобы женщины вышли из ал ##тар ##я [UNK] Под ##а ##ёт свят ##ое \u001b[91mмир\u001b[0m ##о . А ##рх ##ие ##рей пом ##азу ##ет крест ##оо ##бра ##зно сначала т ##ра ##пе ##зу в тех местах , где во время лит ##ург ##ии стоит е ##ван ##гел ##ие , диск ##ос и по ##ти ##р . [SEP]\n",
      "[CLS] Они в ##езде одним м ##v ##ром ма ##зан ##ы . М ##v ##ром по ##крыт ( т . е . пом ##азан ) , с \u001b[91mмир\u001b[0m ##ом за ##с ##пит . Р ##ого ##ж ##цы в [SEP]\n",
      "[CLS] М ##о ##щи святого х ##ран ##ятся здесь до сих пор , про ##до ##лж ##ая исто ##чать \u001b[91mмир\u001b[0m ##о . [SEP]\n",
      "[CLS] И ##осиф у ##вид ##ел , что по и ##кон ##е Бог ##оро ##ди ##цы тек ##ли стр ##уй ##ки \u001b[91mмира\u001b[0m , которое и изд ##ава ##ло б ##лаг ##оу ##хан ##ие . [SEP]\n",
      "миро\n",
      "[CLS] К ##аза ##лось , перед р ##ево ##лю ##цией у ##де ##сят ##ери ##лось о ##жи ##дание , пред ##чу ##в ##ствие , пред ##вид ##ение золото ##го века , р ##ая на земле ; каз ##алось , вся ду ##ша на ##ции и ##сс ##туп ##лен ##но бр ##еди ##ла и гр ##ези ##ла чем - то един ##ым , в котором с ##п ##лета ##лись не ##рас ##тор ##жим ##о смерть и б ##есс ##мер ##тие , золотой век и ги ##бель , \u001b[91mмог\u001b[0m ##иль ##ный м ##рак и ос ##леп ##ительный свет [UNK] [SEP]\n",
      "[CLS] И первое время в о ##фи ##са ##х трёх компаний сто ##яла \u001b[91mмог\u001b[0m ##иль ##ная ти ##шина , сотрудник ##и об ##щал ##ись друг с другом за ##пис ##очка ##ми , только с ##к ##ри ##пели пер ##ья . [SEP]\n",
      "[CLS] Я по ##гла ##дил ##а сум ##ку , даже через за ##м ##шу рук ##а о ##щу ##тил ##а \u001b[91mмог\u001b[0m ##иль ##ный х ##оло ##д п ##ист ##оле ##та . [SEP]\n",
      "[CLS] памятник , - за ##пах , - на ##я ти ##шина . К ##ом \u001b[91mмог\u001b[0m ##иль ##ной земли к се ##рд ##цу , с ##кор ##б ##ь от ##ля ##же ##т . [SEP]\n",
      "[CLS] М ##оло ##ток ле ##жит на ок ##не [UNK] должно быть , им при ##бива ##ют к \u001b[91mмог\u001b[0m ##иль ##ным крест ##ам до ##ще ##чки . [SEP]\n",
      "10. мог not found, taking [CLS] token... (['М', '##оги', '##льные', 'п', '##лит', '##ы', 'на', 'сто', '##лично', '##м', 'по', '##го', '##сте', 'за', '##рос', '##ли', 'бу', '##рь', '##ян', '##ом', ',', 'крест', '##ы', 'под', '##ко', '##сили', '##сь', ',', 'всё', 'каз', '##алось', 'пов', '##ален', '##ным', 'или', 'при', '##дав', '##лен', '##ным', '.'])\n",
      "\u001b[91m[CLS]\u001b[0m М ##оги ##льные п ##лит ##ы на сто ##лично ##м по ##го ##сте за ##рос ##ли бу ##рь ##ян ##ом , крест ##ы под ##ко ##сили ##сь , всё каз ##алось пов ##ален ##ным или при ##дав ##лен ##ным . [SEP]\n",
      "[CLS] Я [UNK] сл ##аб ##ый , б ##ед ##ный уз ##ник , Что через час за ##с ##н ##ёт \u001b[91mмог\u001b[0m ##иль ##ным с ##ном [UNK] [SEP]\n",
      "могильный\n",
      "[CLS] За ##то она очень л ##ю ##била мы ##ть пол ##ы и исп ##ол ##нял ##а это за ##нятие так часто и с таким усе ##рди ##ем , что в кв ##арт ##ире скоро за ##вела ##сь с ##ыр ##ость и показали ##сь \u001b[91mм\u001b[0m ##ок ##ри ##цы . [SEP]\n",
      "[CLS] [UNK] З ##нае ##шь , до встречи с то ##бой я была така ##я т ##рус ##их ##а , правда , я л ##ы ##жни ##ца и п ##лава ##ю хорошо , у меня первый раз ##ряд , но всё равно я т ##рус ##их ##а , мы ##шей бою ##сь , и \u001b[91mм\u001b[0m ##ок ##ри ##ц , и со ##рок ##он ##оже ##к . [SEP]\n",
      "[CLS] Р ##еб ##яти ##шки , что \u001b[91mм\u001b[0m ##ок ##ри ##цы от с ##ыр ##ости раз ##водятся . [SEP]\n",
      "[CLS] О ##чень долго ( до 15 - 20 лет ) могут со ##х ##ран ##яться в по ##ч ##ве се ##мена со ##рн ##як ##ов : ле ##бед ##ы , ма ##ри , \u001b[91mм\u001b[0m ##ок ##ри ##цы . [SEP]\n",
      "[CLS] В сад ##ике - двор ##ике мал ##ень ##кие к ##лён ##ы , за ##рос ##шая \u001b[91mм\u001b[0m ##ок ##ри ##цей и под ##оро ##жни ##ком уз ##кая т ##ро ##пи ##нка вокруг не ##ров ##ного бу ##гра . [SEP]\n",
      "[CLS] О ##пределение слова \u001b[91mм\u001b[0m ##ок ##ри ##ца : бо ##тан . одно ##лет ##нее т ##рав ##ян ##ист ##ое со ##рно ##е р ##астение семейства г ##во ##зди ##чных с ле ##жа ##чим ##и ст ##еб ##лями и м ##ел ##кими бел ##ыми звёзд ##чат ##ыми цвет ##очка ##ми , р ##аст ##у ##щее в с ##ыры ##х и за ##тен ##ённых местах ( Stella ##ria media ) [SEP]\n",
      "[CLS] \u001b[91mм\u001b[0m ##ок ##ри ##ца , м ##ок ##ри ##чка , [SEP]\n",
      "[CLS] О ##пределение слова \u001b[91mм\u001b[0m ##ок ##ри ##ца : То ##п ##тун , Pol ##yg ##onu ##m av ##icular ##e , с ##пор ##ыш , бр ##ыл ##ёна . [SEP]\n",
      "мокрица\n",
      "[CLS] Но только что он у ##с ##по ##ко ##ился в своей по ##зе , как над сто ##лом про ##лет ##ела \u001b[91mм\u001b[0m ##оль . [SEP]\n",
      "[CLS] \u001b[91mм\u001b[0m ##оль ш ##уб ##ная , п ##лат ##яна ##я , с ##ыр ##ная , [SEP]\n",
      "[CLS] М ##оль ово ##щ ##ная , т ##ля , \u001b[91mм\u001b[0m ##оты ##лица , м ##ет ##лица , которой г ##ус ##ени ##ца по ##еда ##ет со ##ты . [ М ##оль , м ##ел ##ю ##з ##га , м ##ело ##чь , из ##ме ##ль ##чо ##нные в ##е ##щи . [SEP]\n",
      "[CLS] О ##пределение слова \u001b[91mм\u001b[0m ##оль : Сам ##ая м ##ел ##кая р ##ы ##бка , не ##давно вы ##ве ##д ##шая ##ся , м ##оль ##га , м ##оль ##ка , м ##оля ##ва , - л ##яв ##ка , мал ##ь ##га , [SEP]\n",
      "[CLS] \u001b[91mм\u001b[0m ##оль ##ю ; [SEP]\n",
      "[CLS] н ##в ##г . самый \u001b[91mм\u001b[0m ##ел ##кий с ##не ##жок . М ##оль од ##еж ##у т ##лит , а п ##еча ##ль се ##рдце ( или человека ) . На ##бива ##й но ##с та ##ба ##чком , в голов ##е м ##оль не за ##веде ##тся ! На з ##уба ##х м ##оз ##оли , но ##гти р ##ас ##пу ##х ##ли , во ##лос ##а м ##оль [SEP]\n",
      "[CLS] О ##пределение слова \u001b[91mм\u001b[0m ##оль : 2 . м . , в му ##зы ##ке мин ##ор или гр ##ус ##тный ла ##д , м ##яг ##кое со ##зв ##уч ##ье , [SEP]\n",
      "[CLS] М ##оль ##ное отношение r [UNK] число \u001b[91mм\u001b[0m ##олей одного комп ##оне ##нта на один м ##оль другого . [SEP]\n",
      "[CLS] О ##чевидно , что \u001b[91mм\u001b[0m ##оль одного вещества во сто ##лько же раз больше м ##оля другого , во с ##колько раз м ##оле ##кула первого тя ##же ##ле ##е м ##оле ##кул ##ы второго . [SEP]\n",
      "[CLS] М [UNK] ма ##сса 1 \u001b[91mм\u001b[0m ##оль р ##аст ##вор ##ённого вещества ( числе ##нно р ##авная м ##оле ##кул ##яр ##ному в ##ес ##у ) , г . [SEP]\n",
      "моль\n",
      "[CLS] Вы ##г ##лян ##ула из две ##ри , пов ##ис ##нув на ко ##сты ##лях , по ##жила ##я , в ##стр ##ё ##пан ##ная , чи ##та ##ет \u001b[91mмора\u001b[0m ##ль . [SEP]\n",
      "[CLS] Она была их у ##те ##ши ##тель ##ницей , ду ##ше ##пр ##ика ##з ##чи ##цей , каз ##на ##че ##ем , ле ##кар ##ем и дух ##овно ##ю ма ##тер ##ью : ей первой б ##ежа ##л солдат ##ик открыт ##ь св ##ое горе , за ##кл ##ю ##чав ##шее ##ся в по ##тер ##е ш ##тыка , или в ин ##ой под ##обно ##й б ##еде , значения которой не по ##нять тому , кто не носи ##л р ##ан ##ца за п ##ле ##ча ##ми , [UNK] и К ##ат ##ерина А ##ста ##ф ##ьев ##на не чи ##тала ни ##ка ##ких \u001b[91mмора\u001b[0m ##лей и нас ##тав ##лений , а прямо пом ##ога ##ла , как на ##ходил ##а во ##зм ##ожным . [SEP]\n",
      "[CLS] С ##ыта ##я \u001b[91mмора\u001b[0m ##ль ар ##од ##н . ду ##рная слава . Про меня мора ##ль по ##шла . Он на меня мора ##ль на ##водит [SEP]\n",
      "[CLS] Се ##го ##дня в наш ##ем об ##ществе нас ##аж ##дается по ##треби ##тель ##ское мир ##ово ##з ##з ##рение , по ##о ##щ ##ря ##ются э ##го ##исти ##ческие у ##стр ##ем ##ления человека , поп ##ира ##ется х ##ристиан ##ская \u001b[91mмора\u001b[0m ##ль с её жертв ##енно ##стью и у ##стр ##ем ##лен ##ностью к вы ##с ##шим и ##де ##ала ##м . [SEP]\n",
      "34. мора not found, taking [CLS] token... (['М', '##ора', '##ль', 'се', '##й', 'бас', '##ни', 'про', '##ста', 'как', 'правда', ':', 'такое', 'в', 'жизни', 'бы', '##вает', ',', 'что', 'ни', 'в', 'с', '##каз', '##ке', 'с', '##каз', '##ать', ',', 'ни', 'пер', '##ом', 'о', '##писать', '!'])\n",
      "\u001b[91m[CLS]\u001b[0m М ##ора ##ль се ##й бас ##ни про ##ста как правда : такое в жизни бы ##вает , что ни в с ##каз ##ке с ##каз ##ать , ни пер ##ом о ##писать ! [SEP]\n",
      "мораль\n"
     ]
    }
   ],
   "source": [
    "embeddings = []\n",
    "orth = \"\"\n",
    "\n",
    "word_idx = 0\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if orth != \"\" and orth != row['word']:\n",
    "        print(f\"{orth}\")\n",
    "        word_idx += 1\n",
    "    if word_idx == 5:\n",
    "        break\n",
    "\n",
    "    orth = row['word']          # target word\n",
    "    word = row['orth']          # usage of the target word in the example\n",
    "    sense_id = row['sense_id']  # sense of the target word in the example\n",
    "    gloss = row['gloss']        # definition of the target word\n",
    "    example = row['example']    # usage example of the target word\n",
    "\n",
    "    tokens = tokenizer.tokenize(example)\n",
    "    tokens_lower = [i.lower() for i in tokenizer.tokenize(example)]\n",
    "\n",
    "    search = get_search(example, word, orth)\n",
    "    search_token = tokenizer.tokenize(search)[0]\n",
    "    target_index = get_target_index(search_token, tokens, tokens_lower)\n",
    "    if target_index == -1:\n",
    "        search = get_search(example, search_token)\n",
    "        search_token = tokenizer.tokenize(search)[0]\n",
    "        target_index = get_target_index(search_token, tokens, tokens_lower)\n",
    "        if target_index == -1:\n",
    "            print(f\"{index}. {search_token} not found, taking [CLS] token... ({tokens})\")\n",
    "            target_index = 0\n",
    "\n",
    "    inputs = tokenizer(example, return_tensors=\"pt\")\n",
    "    print_nice(inputs['input_ids'][0], target_index)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        input_ids = inputs[\"input_ids\"].to(device)\n",
    "        attention_mask = inputs[\"attention_mask\"].to(device)\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, output_hidden_states=True)\n",
    "    \n",
    "    df.at[index, 'embedding'] = outputs.last_hidden_state[0][target_index]/torch.norm(outputs.last_hidden_state[0][target_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6494 entries, 0 to 6493\n",
      "Data columns (total 10 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   usage_id              6494 non-null   object \n",
      " 1   word                  6494 non-null   object \n",
      " 2   orth                  6494 non-null   object \n",
      " 3   sense_id              6494 non-null   object \n",
      " 4   gloss                 6494 non-null   object \n",
      " 5   example               6494 non-null   object \n",
      " 6   indices_target_token  0 non-null      float64\n",
      " 7   date                  6493 non-null   object \n",
      " 8   period                6493 non-null   object \n",
      " 9   embedding             35 non-null     object \n",
      "dtypes: float64(1), object(9)\n",
      "memory usage: 507.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['embedding'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans, AffinityPropagation\n",
    "\n",
    "def get_silhouette_score(tensors, labels):\n",
    "    # Convert the torch tensors to numpy arrays and reshape them\n",
    "    X = np.array([tensor.flatten().numpy() for tensor in tensors])\n",
    "    # Calculate the silhouette score\n",
    "    score = silhouette_score(X, labels=labels, metric='euclidean')\n",
    "    return score\n",
    "\n",
    "def KMeans_clustering(df):\n",
    "    best_score = -1\n",
    "    best_n = 0\n",
    "    min_senses = df['sense_id'].nunique()\n",
    "    max_senses = min_senses + df['sense_id'].isnull().sum()\n",
    "    for n in range(min_senses,max_senses):\n",
    "        kmeans = KMeans(n_clusters=n, random_state=0)\n",
    "        kmeans.fit(df['embedding'].tolist())\n",
    "        df[f'clusters_{n}'] = None\n",
    "        df[f'clusters_{n}'] = kmeans.labels_\n",
    "        silhouette_avg = get_silhouette_score(df['embedding'], df[f'clusters_{n}'])\n",
    "        if silhouette_avg > best_score:\n",
    "            best_score = silhouette_avg\n",
    "            best_n = n\n",
    "    print(\"Best number of clusters:\", best_n)\n",
    "    df['clusters'] = df[f'clusters_{best_n}']\n",
    "    df = df.drop(columns=[f'clusters_{n}' for n in range(min_senses,max_senses)])\n",
    "    return df\n",
    "\n",
    "def AffinityPropagation_clustering(df):\n",
    "    ap = AffinityPropagation()\n",
    "    clusters = ap.fit(df['embedding'].tolist())\n",
    "    df['clusters'] = None\n",
    "    df['clusters'] = clusters.labels_\n",
    "    return df\n",
    "\n",
    "def clustering(df, method=\"AffinityPropagation\"):\n",
    "    if method == \"KMeans\":\n",
    "        return KMeans_clustering(df)\n",
    "    elif method == \"AffinityPropagation\":\n",
    "        return AffinityPropagation_clustering(df)\n",
    "    else:\n",
    "        print(\"Invalid clustering method\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: миро\n",
      "label: могильный\n",
      "label: мокрица\n",
      "label: моль\n",
      "label: мораль\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for label, group in df.groupby('word'):\n",
    "    print(\"label:\", label)\n",
    "    result_df = clustering(group, method=\"KMeans\")\n",
    "    result_df\n",
    "    counter+=1\n",
    "    if counter == 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>usage_id</th>\n",
       "      <th>word</th>\n",
       "      <th>orth</th>\n",
       "      <th>sense_id</th>\n",
       "      <th>gloss</th>\n",
       "      <th>example</th>\n",
       "      <th>indices_target_token</th>\n",
       "      <th>date</th>\n",
       "      <th>period</th>\n",
       "      <th>embedding</th>\n",
       "      <th>clusters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>train_ru_43</td>\n",
       "      <td>мораль</td>\n",
       "      <td>мораль</td>\n",
       "      <td>moral'_L9xfEoeFqW8</td>\n",
       "      <td>исч., разг. нравоучение, наставление</td>\n",
       "      <td>Выглянула из двери, повиснув на костылях, пожи...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>new</td>\n",
       "      <td>new</td>\n",
       "      <td>[tensor(-0.0339), tensor(-0.0134), tensor(0.01...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>train_ru_44</td>\n",
       "      <td>мораль</td>\n",
       "      <td>мораль</td>\n",
       "      <td>moral'_L9xfEoeFqW8</td>\n",
       "      <td>исч., разг. нравоучение, наставление</td>\n",
       "      <td>Она была их утешительницей, душеприказчицей, к...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>new</td>\n",
       "      <td>new</td>\n",
       "      <td>[tensor(0.0087), tensor(0.0066), tensor(-0.017...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>train_ru_45</td>\n",
       "      <td>мораль</td>\n",
       "      <td>мораль</td>\n",
       "      <td>moral'_L9xfEoeFqW8</td>\n",
       "      <td>исч., разг. нравоучение, наставление</td>\n",
       "      <td>Сытая мораль ародн. дурная слава. Про меня мор...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>old</td>\n",
       "      <td>old</td>\n",
       "      <td>[tensor(-0.0548), tensor(0.0365), tensor(0.048...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>train_ru_46</td>\n",
       "      <td>мораль</td>\n",
       "      <td>мораль</td>\n",
       "      <td>moral'_L9xfEoeFqW8</td>\n",
       "      <td>исч., разг. нравоучение, наставление</td>\n",
       "      <td>Сегодня в нашем обществе насаждается потребите...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>new</td>\n",
       "      <td>new</td>\n",
       "      <td>[tensor(-0.0489), tensor(0.0271), tensor(0.033...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>train_ru_47</td>\n",
       "      <td>мораль</td>\n",
       "      <td>мораль</td>\n",
       "      <td>moral'_eKPPBHOtdOI</td>\n",
       "      <td>исч. вывод из чего-нибудь; нравственный урок</td>\n",
       "      <td>Мораль сей басни проста как правда: такое в жи...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>new</td>\n",
       "      <td>new</td>\n",
       "      <td>[tensor(-0.0203), tensor(0.0253), tensor(-0.00...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       usage_id    word    orth            sense_id  \\\n",
       "30  train_ru_43  мораль  мораль  moral'_L9xfEoeFqW8   \n",
       "31  train_ru_44  мораль  мораль  moral'_L9xfEoeFqW8   \n",
       "32  train_ru_45  мораль  мораль  moral'_L9xfEoeFqW8   \n",
       "33  train_ru_46  мораль  мораль  moral'_L9xfEoeFqW8   \n",
       "34  train_ru_47  мораль  мораль  moral'_eKPPBHOtdOI   \n",
       "\n",
       "                                           gloss  \\\n",
       "30          исч., разг. нравоучение, наставление   \n",
       "31          исч., разг. нравоучение, наставление   \n",
       "32          исч., разг. нравоучение, наставление   \n",
       "33          исч., разг. нравоучение, наставление   \n",
       "34  исч. вывод из чего-нибудь; нравственный урок   \n",
       "\n",
       "                                              example  indices_target_token  \\\n",
       "30  Выглянула из двери, повиснув на костылях, пожи...                   NaN   \n",
       "31  Она была их утешительницей, душеприказчицей, к...                   NaN   \n",
       "32  Сытая мораль ародн. дурная слава. Про меня мор...                   NaN   \n",
       "33  Сегодня в нашем обществе насаждается потребите...                   NaN   \n",
       "34  Мораль сей басни проста как правда: такое в жи...                   NaN   \n",
       "\n",
       "   date period                                          embedding  clusters  \n",
       "30  new    new  [tensor(-0.0339), tensor(-0.0134), tensor(0.01...         1  \n",
       "31  new    new  [tensor(0.0087), tensor(0.0066), tensor(-0.017...         0  \n",
       "32  old    old  [tensor(-0.0548), tensor(0.0365), tensor(0.048...         1  \n",
       "33  new    new  [tensor(-0.0489), tensor(0.0271), tensor(0.033...         1  \n",
       "34  new    new  [tensor(-0.0203), tensor(0.0253), tensor(-0.00...         2  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

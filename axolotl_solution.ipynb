{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.cluster import KMeans, AffinityPropagation\n",
    "from sklearn.metrics import silhouette_score\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load the data and the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fi', './embeddings/concatenated/axolotl.test.fi.json')"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FILE_TO_READ = './data/dev-testing/axolotl.dev.fi.tsv'\n",
    "EMBEDDING_TYPE = 'glosses' # 'examples', 'glosses' or 'concatenated'\n",
    "PRINT_WORDS = False\n",
    "CLUSTERING_METHOD = 'KMeans' # 'KMeans' or 'AffinityPropagation'\n",
    "\n",
    "language = FILE_TO_READ.split('.')[-2]\n",
    "filename = FILE_TO_READ.split('/')[-1].split('.')[0:-1]\n",
    "filename = '.'.join(filename)\n",
    "embeddings_file = f\"./embeddings/{EMBEDDING_TYPE}/{filename}.json\"\n",
    "language, embeddings_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7224 entries, 0 to 7223\n",
      "Data columns (total 9 columns):\n",
      " #   Column                Non-Null Count  Dtype \n",
      "---  ------                --------------  ----- \n",
      " 0   usage_id              7224 non-null   object\n",
      " 1   word                  7224 non-null   object\n",
      " 2   orth                  7224 non-null   object\n",
      " 3   sense_id              3960 non-null   object\n",
      " 4   gloss                 7224 non-null   object\n",
      " 5   example               7224 non-null   object\n",
      " 6   indices_target_token  7224 non-null   object\n",
      " 7   date                  7224 non-null   int64 \n",
      " 8   period                7224 non-null   object\n",
      "dtypes: int64(1), object(8)\n",
      "memory usage: 508.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(FILE_TO_READ, sep='\\t')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting ',' delimiter: line 1 column 126627656 (char 126627655)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[148], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(embeddings_file, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m json_file:\n\u001b[1;32m----> 2\u001b[0m     embeddings_list \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(embeddings_list)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m embeddings\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m df\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEmbeddings count must be the same as the df length\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\json\\__init__.py:293\u001b[0m, in \u001b[0;36mload\u001b[1;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(fp, \u001b[38;5;241m*\u001b[39m, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, object_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, parse_float\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    275\u001b[0m         parse_int\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, parse_constant\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, object_pairs_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[0;32m    276\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;124;03m    a JSON document) to a Python object.\u001b[39;00m\n\u001b[0;32m    278\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;124;03m    kwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[0;32m    292\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobject_hook\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobject_hook\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_float\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparse_int\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_int\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_constant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_constant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobject_pairs_hook\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobject_pairs_hook\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\json\\__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[1;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\json\\decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[0;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[0;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\json\\decoder.py:353\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Decode a JSON document from ``s`` (a ``str`` beginning with\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;124;03ma JSON document) and return a 2-tuple of the Python\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;124;03mrepresentation and the index in ``s`` where the document ended.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    350\u001b[0m \n\u001b[0;32m    351\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscan_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting ',' delimiter: line 1 column 126627656 (char 126627655)"
     ]
    }
   ],
   "source": [
    "with open(embeddings_file, 'r') as json_file:\n",
    "    embeddings_list = json.load(json_file)\n",
    "\n",
    "embeddings = torch.tensor(embeddings_list)\n",
    "assert embeddings.shape[0] == df.shape[0], \"Embeddings count must be the same as the df length\"\n",
    "embeddings.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['embedding'] = list(embeddings)\n",
    "assert all(df['embedding'][0] == embeddings[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Clustering algorithm with the embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_silhouette_score(tensors, labels):\n",
    "    X = np.array([tensor.flatten().numpy() for tensor in tensors])\n",
    "    score = silhouette_score(X, labels=labels, metric='euclidean')\n",
    "    return score\n",
    "\n",
    "def KMeans_clustering(df):\n",
    "    best_score = -1\n",
    "    best_n = 0\n",
    "    min_senses = df['sense_id'].nunique()\n",
    "    max_senses = min_senses + df['sense_id'].isnull().sum()\n",
    "\n",
    "    for n in range(min_senses,max_senses):\n",
    "        kmeans = KMeans(n_clusters=n, random_state=0, n_init='auto')\n",
    "        kmeans.fit(df['embedding'].tolist())\n",
    "        df[f'cluster_{n}'] = None\n",
    "        df[f'cluster_{n}'] = kmeans.labels_\n",
    "        try:\n",
    "            silhouette_avg = get_silhouette_score(df['embedding'], df[f'cluster_{n}']) if n > 1 else 0 # TODO: Esto es correcto, sí debería ser 0?\n",
    "        except Exception as e:\n",
    "            # this happens with glooses because they may have exactly the same embedding\n",
    "            silhouette_avg = 1e6 # very high value\n",
    "            #raise e\n",
    "        if silhouette_avg > best_score:\n",
    "            best_score = silhouette_avg\n",
    "            best_n = n\n",
    "\n",
    "    if PRINT_WORDS:\n",
    "        print(\"Best number of clusters:\", best_n, f\"[{min_senses}-{max_senses}]\")\n",
    "    df['cluster'] = df[f'cluster_{best_n}']\n",
    "    df = df.drop(columns=[f'cluster_{n}' for n in range(min_senses,max_senses)])\n",
    "    return df\n",
    "\n",
    "def AffinityPropagation_clustering(df):\n",
    "    ap = AffinityPropagation()\n",
    "    clusters = ap.fit(df['embedding'].tolist())\n",
    "    df['cluster'] = None\n",
    "    df['cluster'] = clusters.labels_\n",
    "    return df\n",
    "\n",
    "def clustering(df, method=\"AffinityPropagation\"):\n",
    "    if method == \"KMeans\":\n",
    "        df_cl = KMeans_clustering(df)\n",
    "    else:\n",
    "        df_cl = AffinityPropagation_clustering(df)\n",
    "\n",
    "    \"\"\"# Transformation code (set sense_id based on cluster) TODO: Error! It's expanding the dataframe, and it shouldn't\n",
    "    mapping = df_cl.groupby('cluster')['sense_id'].apply(lambda x: x.dropna().unique()).to_dict()\n",
    "    df_cl['sense_id'] = df_cl['sense_id'].fillna(df_cl['cluster'].map(mapping))\n",
    "    df_cl = df_cl.explode('sense_id')\n",
    "\n",
    "    df_cl.loc[df_cl['sense_id'].isna(), 'sense_id'] = df_cl.loc[df_cl['sense_id'].isna(), 'cluster']\n",
    "    df_cl.drop(columns=['cluster'], inplace=True)\n",
    "    df_cl.reset_index(drop=True, inplace=True)\"\"\"\n",
    "    \n",
    "    # 1. Save the cluster values\n",
    "\n",
    "    # 2. If sense_id is not null, set cluster to sense_id\n",
    "    clusters_replaced = df_cl.loc[~df_cl['sense_id'].isna(), 'cluster']\n",
    "    clusters_names = df_cl.loc[~df_cl['sense_id'].isna(), 'sense_id']\n",
    "\n",
    "    for index, value in clusters_replaced.items():\n",
    "        df_cl.loc[df_cl['cluster'] == value, 'cluster'] = clusters_names[index]\n",
    "    \n",
    "    df_cl['sense_id'] = df_cl['cluster']\n",
    "    df_cl.drop(columns=['cluster', 'embedding'], inplace=True)\n",
    "\n",
    "    return df_cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>usage_id</th>\n",
       "      <th>word</th>\n",
       "      <th>orth</th>\n",
       "      <th>sense_id</th>\n",
       "      <th>gloss</th>\n",
       "      <th>example</th>\n",
       "      <th>indices_target_token</th>\n",
       "      <th>date</th>\n",
       "      <th>period</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_fi_0</td>\n",
       "      <td>palaus</td>\n",
       "      <td>palaus</td>\n",
       "      <td>4</td>\n",
       "      <td>\"Palaus\" tässä esimerkissä tarkoittaa paluuta ...</td>\n",
       "      <td>Tobian palaus cotia murhellisten wanhembainsa ...</td>\n",
       "      <td>7:13</td>\n",
       "      <td>1750</td>\n",
       "      <td>new</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_fi_1</td>\n",
       "      <td>palaus</td>\n",
       "      <td>palaus</td>\n",
       "      <td>4</td>\n",
       "      <td>Palaus tarkoittaa tässä yhteydessä paluuta tai...</td>\n",
       "      <td>Teidän Cuning:sen Maj:tinne palaus, Teidän ja ...</td>\n",
       "      <td>28:34</td>\n",
       "      <td>1750</td>\n",
       "      <td>new</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_fi_2</td>\n",
       "      <td>palaus</td>\n",
       "      <td>palauxesta</td>\n",
       "      <td>palaus_CWRkn3_kCjQ</td>\n",
       "      <td>paluu</td>\n",
       "      <td>[Seuraava teksti] On opetuslasten palauxesta J...</td>\n",
       "      <td>34:44</td>\n",
       "      <td>1600</td>\n",
       "      <td>old</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_fi_3</td>\n",
       "      <td>palaus</td>\n",
       "      <td>Palaus</td>\n",
       "      <td>4</td>\n",
       "      <td>\"Palaus\" tarkoittaa tässä esimerkissä siirtymi...</td>\n",
       "      <td>ettei sencallainen Sijrtyminen, Palaus ja Känd...</td>\n",
       "      <td>32:38</td>\n",
       "      <td>1700</td>\n",
       "      <td>new</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_fi_4</td>\n",
       "      <td>palaus</td>\n",
       "      <td>palaus</td>\n",
       "      <td>palaus_ef0RFR9a4Ac</td>\n",
       "      <td>kääntymys, hengellinen kääntyminen</td>\n",
       "      <td>anna minulle yxi oikea catumus ia synnistä palaus</td>\n",
       "      <td>43:49</td>\n",
       "      <td>1543</td>\n",
       "      <td>old</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7219</th>\n",
       "      <td>arificial_test_fi_7241</td>\n",
       "      <td>mutka</td>\n",
       "      <td>mutcain</td>\n",
       "      <td>mutka_OOpbXCuf97s</td>\n",
       "      <td>laulun sävelkulusta</td>\n",
       "      <td>Kappaleen sävelkulku kulkee tasaisesti eteenpä...</td>\n",
       "      <td>24:31</td>\n",
       "      <td>1600</td>\n",
       "      <td>old</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7220</th>\n",
       "      <td>arificial_test_fi_7242</td>\n",
       "      <td>mutka</td>\n",
       "      <td>mutcain</td>\n",
       "      <td>mutka_OOpbXCuf97s</td>\n",
       "      <td>laulun sävelkulusta</td>\n",
       "      <td>Laulun sävelkulku sisältää useita mutkia, kun ...</td>\n",
       "      <td>24:31</td>\n",
       "      <td>1600</td>\n",
       "      <td>old</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7221</th>\n",
       "      <td>arificial_test_fi_7243</td>\n",
       "      <td>mutka</td>\n",
       "      <td>mutkall</td>\n",
       "      <td>mutka_HsIpNwQCuO8</td>\n",
       "      <td>juoni, temppu, metku</td>\n",
       "      <td>Hän suunnitteli pienen mutkan auton eteen, jot...</td>\n",
       "      <td>59:66</td>\n",
       "      <td>1600</td>\n",
       "      <td>old</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7222</th>\n",
       "      <td>arificial_test_fi_7244</td>\n",
       "      <td>mutka</td>\n",
       "      <td>mutkall</td>\n",
       "      <td>mutka_HsIpNwQCuO8</td>\n",
       "      <td>juoni, temppu, metku</td>\n",
       "      <td>Lapsi veti hauskan mutkan, jotta voisi voittaa...</td>\n",
       "      <td>59:66</td>\n",
       "      <td>1600</td>\n",
       "      <td>old</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7223</th>\n",
       "      <td>arificial_test_fi_7245</td>\n",
       "      <td>neuloa</td>\n",
       "      <td>neulomahan</td>\n",
       "      <td>neuloa_rYtfFv0X8yQ</td>\n",
       "      <td>ommella, kirjailla</td>\n",
       "      <td>Hän istui sohvalla ja neuloi kauniin kukkakuvi...</td>\n",
       "      <td>53:63</td>\n",
       "      <td>1650</td>\n",
       "      <td>old</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7224 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    usage_id    word        orth            sense_id  \\\n",
       "0                  test_fi_0  palaus      palaus                   4   \n",
       "1                  test_fi_1  palaus      palaus                   4   \n",
       "2                  test_fi_2  palaus  palauxesta  palaus_CWRkn3_kCjQ   \n",
       "3                  test_fi_3  palaus      Palaus                   4   \n",
       "4                  test_fi_4  palaus      palaus  palaus_ef0RFR9a4Ac   \n",
       "...                      ...     ...         ...                 ...   \n",
       "7219  arificial_test_fi_7241   mutka     mutcain   mutka_OOpbXCuf97s   \n",
       "7220  arificial_test_fi_7242   mutka     mutcain   mutka_OOpbXCuf97s   \n",
       "7221  arificial_test_fi_7243   mutka     mutkall   mutka_HsIpNwQCuO8   \n",
       "7222  arificial_test_fi_7244   mutka     mutkall   mutka_HsIpNwQCuO8   \n",
       "7223  arificial_test_fi_7245  neuloa  neulomahan  neuloa_rYtfFv0X8yQ   \n",
       "\n",
       "                                                  gloss  \\\n",
       "0     \"Palaus\" tässä esimerkissä tarkoittaa paluuta ...   \n",
       "1     Palaus tarkoittaa tässä yhteydessä paluuta tai...   \n",
       "2                                                 paluu   \n",
       "3     \"Palaus\" tarkoittaa tässä esimerkissä siirtymi...   \n",
       "4                    kääntymys, hengellinen kääntyminen   \n",
       "...                                                 ...   \n",
       "7219                                laulun sävelkulusta   \n",
       "7220                                laulun sävelkulusta   \n",
       "7221                               juoni, temppu, metku   \n",
       "7222                               juoni, temppu, metku   \n",
       "7223                                 ommella, kirjailla   \n",
       "\n",
       "                                                example indices_target_token  \\\n",
       "0     Tobian palaus cotia murhellisten wanhembainsa ...                 7:13   \n",
       "1     Teidän Cuning:sen Maj:tinne palaus, Teidän ja ...                28:34   \n",
       "2     [Seuraava teksti] On opetuslasten palauxesta J...                34:44   \n",
       "3     ettei sencallainen Sijrtyminen, Palaus ja Känd...                32:38   \n",
       "4     anna minulle yxi oikea catumus ia synnistä palaus                43:49   \n",
       "...                                                 ...                  ...   \n",
       "7219  Kappaleen sävelkulku kulkee tasaisesti eteenpä...                24:31   \n",
       "7220  Laulun sävelkulku sisältää useita mutkia, kun ...                24:31   \n",
       "7221  Hän suunnitteli pienen mutkan auton eteen, jot...                59:66   \n",
       "7222  Lapsi veti hauskan mutkan, jotta voisi voittaa...                59:66   \n",
       "7223  Hän istui sohvalla ja neuloi kauniin kukkakuvi...                53:63   \n",
       "\n",
       "      date period  \n",
       "0     1750    new  \n",
       "1     1750    new  \n",
       "2     1600    old  \n",
       "3     1700    new  \n",
       "4     1543    old  \n",
       "...    ...    ...  \n",
       "7219  1600    old  \n",
       "7220  1600    old  \n",
       "7221  1600    old  \n",
       "7222  1600    old  \n",
       "7223  1650    old  \n",
       "\n",
       "[7224 rows x 9 columns]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = pd.DataFrame()\n",
    "for word, group in df.groupby('word'):\n",
    "    if PRINT_WORDS:\n",
    "        print(f\"{word}: \", end=\"\")\n",
    "    group_cl = clustering(group, method=CLUSTERING_METHOD)\n",
    "    result_df = pd.concat([result_df, group_cl], ignore_index=True)\n",
    "    if len(group) != len(group_cl):\n",
    "        print(f\"{len(group)} != {len(group_cl)} for word {word}\")\n",
    "\n",
    "# TODO: reorder result_df, in the same order of usage_id in the original df\n",
    "result_df = result_df.set_index('usage_id')\n",
    "result_df = result_df.reindex(df['usage_id'])\n",
    "result_df = result_df.reset_index()\n",
    "\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the results_df to a tsv file\n",
    "result_df.to_csv(f'./predictions/{filename}-{EMBEDDING_TYPE}-{CLUSTERING_METHOD}.tsv', sep='\\t', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
